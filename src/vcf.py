import pandas as pd
import numpy as np
import vcfpy
import os

def readVCF(vcf):
    """
    function to read annotated vcf files generated by snpEff (per chromosome)  
    outputs dictionary of all variant ids and protein coding annotations - not limited to exonic
    """
    dict = {
        'chrom' : [],
        'pos' : [],
        'id' : [],
        'ann' : [],
        'gene' : [],
        'biotype' : []
    }

    vcf_reader = vcfpy.Reader.from_path(vcf)

    for line in vcf_reader:

        annotations = line.INFO.get('ANN',[]) ## INFO -- dictionary with ANN as key to list of '|' delimited strings, each annotation is an element in the list

        annotations = [a for a in annotations if 'protein_coding' in a or 'intergenic_region' in a] ## extract variants that have annotations to protein coding genes

        for anno in annotations: ## then loop the annotations
 
            fields = anno.split('|')

            dict['chrom'].append(line.CHROM)
            dict['pos'].append(line.POS)
            dict['id'].append(line.ID[0])
            
            dict['ann'].append(fields[1])
            dict['gene'].append(fields[4])
            dict['biotype'].append(fields[7])

    return(dict)


def subsetVariants(model_id, annotated_variants):
    """
    function to take a pgs catalog model id, download the scoring file and subset the annoated variant table 
    """
    dtype_dict = {
        'rsID': str,
        'chr_name': str,
        'chr_position': 'Int64',
        'hm_chr': str,
        'hm_pos': 'Int64',
        'hm_rsID': str,
    } 

    if type(annotated_variants) is str:
        annotated_variants = pd.read_csv(annotated_variants, index_col = 0)

    base_url="https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/ID/ScoringFiles/Harmonized/ID_hmPOS_GRCh37.txt.gz"

    url = base_url.replace('ID', model_id)

    print(f'getting annotated variants for {model_id}... @ {url}')

    pgs_df = pd.read_csv(url, ## download score file
                         compression='gzip', 
                         sep='\t', 
                         comment='#', 
                         low_memory=False, 
                         dtype=dtype_dict, na_values=['NA', 'na', ''])

    score_variants = len(pgs_df['rsID'].unique())
    print(f'{model_id} score file has {score_variants} unique variants...')
    subset = annotated_variants[annotated_variants['id_x'].isin(pgs_df['rsID'])]## renamed to id_x after nodenorm there are 2 id cols, id_x (rsid) id_y (ensembl or ncbi)
    unique_variants = len(subset['id_x'].unique()) 
    print(f'There are {len(subset['id_x'])} variants and {unique_variants} unique variants in genotype subset.')
    return(subset)


if __name__ == '__main__':
    if os.path.isfile('data/bct_variant_annotated.csv'):
        id = 'PGS001990'
        subset = subsetVariants(id, 'data/bct_variant_annotated.csv')
        subset.to_csv(f'data/{id}.csv', index = False)

    else:     
        chrs = list(range(1,23)) + ['X']
    #    chrs = [1]

        base_path = "vcf-GRCh37/ukb_imp_chr_bct_vars_clean.ann.vcf"
        dfs = []
        for chr in chrs:
            vcf_file = base_path.replace('chr',f'chr{chr}')
            dict = readVCF(vcf_file)

            dfs.append(pd.DataFrame.from_dict(dict))

        df = pd.concat(dfs)

        df.to_csv('data/bct_variant_annotated.csv', index = False)

        unique_variants = len(df['id'].unique()) 
        print(f'{unique_variants} unique variants after compiling')
    #    print(df)

